# -*- coding: utf-8 -*-
"""final project code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NASdohN3-zfTZ3_wM019tnIM3hVmQA4I
"""

#for loading data and for performing data analysis operations on it
import pandas as pd
import numpy as np

#for data visualization
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import*
#for file operations
import os

print("All required libraries loaded!")

data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data.csv', index_col=False)
data.shape

data.dtypes

data.head()

data.tail()

X = data.iloc[:,2:32]
print(X.shape)
X.head()

y = data.diagnosis
print(y.shape)
y.head()

y_numb = pd.get_dummies(y)
y_numb.tail()

y = y_numb.M
print(y.shape)
y.tail()

X.corr()

plt.figure(figsize=(18, 12))
sns.heatmap(X.corr(), vmin=0.85, vmax=1, annot=True, cmap='YlGnBu', linewidths=.5)

#for PCA (feature engineering)
from sklearn.decomposition import PCA

#for data scaling
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled)
X_scaled_drop = X_scaled.drop(X_scaled.columns[[2, 3, 12, 13, 22, 23]], axis=1)
pca = PCA(n_components=0.95)
x_pca = pca.fit_transform(X_scaled_drop)
x_pca = pd.DataFrame(x_pca)
print("Before PCA, X dataframe shape = ",X.shape,"\nAfter PCA, x_pca dataframe shape = ",x_pca.shape)

print(pca.explained_variance_ratio_)
print(pca.explained_variance_ratio_.sum())

colnames = ['Pc1','Pc2','Pc3','Pc4','Pc5','Pc6','Pc7','Pc8','Pc9','Pc10','Pc11','diagnosis']
diag = data.iloc[:,1:2]
Xy = pd.DataFrame(np.hstack([x_pca,diag.values]),columns=colnames)
Xy.head()

#for splitting dataset
from sklearn.model_selection import train_test_split
X=(Xy.iloc[:,0:11]).values
#75:25 train:test data splitting
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

print("X_train shape ",X_train.shape)
print("y_train shape ",y_train.shape)
print("X_test shape ",X_test.shape)
print("y_test shape ",y_test.shape)

from sklearn.svm import SVC
svc = SVC()
svc.fit(X_train, y_train)
y_pred_svc1 =svc.predict(X_test)
#y_pred_svc1.shape

y_pred_svc2=svc.decision_function(X_test)

#for displaying evaluation metrics
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
CM = confusion_matrix(y_test, y_pred_svc1)
print("Confusion matrix:\n",CM)
sns.heatmap(CM/np.sum(CM),annot=True,fmt='.2%',cmap='Blues')
plt.show()

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred_svc1))
creport = classification_report(y_test, y_pred_svc1)
print("Classification report:\n",creport)

# PCA -> SVM -> K-FOLD(5,10)

#X = df.iloc[:, 2:32].values
#y = df. iloc [:, 1].values
print("Matrix of features", X, sep='\n')
print("--------------------------------------------------")
print("Target Variable", y, sep='\n')

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
encoded_y = label_encoder.fit_transform(y)
label_encoder_name_mapping = dict(zip(label_encoder.classes_,
                                     label_encoder.transform(label_encoder.classes_)))
print("Mapping of Label Encoded Classes", label_encoder_name_mapping, sep="\n")
print("Label Encoded Target Variable", encoded_y, sep="\n")

from sklearn.model_selection import cross_validate

def Cross_validating(model, _X, _y, _cv=5):
    _scoring = ['accuracy', 'precision', 'recall', 'f1']
    results = cross_validate(estimator=model,
                           X=_X,
                           y=_y,
                           cv=_cv,
                           scoring=_scoring,
                           return_train_score=True)

    return {"Training Accuracy scores": results['train_accuracy'],
          "Mean Training Accuracy": results['train_accuracy'].mean()*100,
          "Training Precision scores": results['train_precision'],
          "Mean Training Precision": results['train_precision'].mean(),
          "Training Recall scores": results['train_recall'],
          "Mean Training Recall": results['train_recall'].mean(),
          "Training F1 scores": results['train_f1'],
          "Mean Training F1 Score": results['train_f1'].mean(),
          "Validation Accuracy scores": results['test_accuracy'],
          "Mean Validation Accuracy": results['test_accuracy'].mean()*100,
          "Validation Precision scores": results['test_precision'],
          "Mean Validation Precision": results['test_precision'].mean(),
          "Validation Recall scores": results['test_recall'],
          "Mean Validation Recall": results['test_recall'].mean(),
          "Validation F1 scores": results['test_f1'],
          "Mean Validation F1 Score": results['test_f1'].mean()
          }

#from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

svc = SVC()
'''svc.fit(X_train, y_train)
y_pred_svc =svc.predict(X_test)
y_pred_svc.shape'''

SVM_result = Cross_validating(svc, X, encoded_y, 10)
print(SVM_result)

def ploting_result(x_label, y_label, plot_title, train_data, val_data):
    print()
    plt.figure(figsize=(12,6))
    labels = ["1st Fold", "2nd Fold", "3rd Fold", "4th Fold", "5th Fold","6th Fold","7th Fold","8th Fold","9th Fold","10th Fold"]
    X_axis = np.arange(len(labels))

    ax = plt.gca()
    plt.ylim(0.40000, 1)
    plt.bar(X_axis-0.2, train_data, 0.4, color='blue', label='Training')
    plt.bar(X_axis+0.2, val_data, 0.4, color='red', label='Validation')

    plt.title(plot_title, fontsize=30)
    plt.xticks(X_axis, labels)
    plt.xlabel(x_label, fontsize=14)
    plt.ylabel(y_label, fontsize=14)
    plt.legend()
    plt.grid(True)
    plt.show()
    print()

def ploting_result(x_label, y_label, plot_title, train_data, val_data):
    print()
    plt.figure(figsize=(12,6))
    labels = ["1st Fold", "2nd Fold", "3rd Fold", "4th Fold", "5th Fold","6th Fold","7th Fold","8th Fold","9th Fold","10th Fold"]
    X_axis = np.arange(len(labels))

    ax = plt.gca()
    plt.ylim(0.40000, 1)
    plt.bar(X_axis-0.2, train_data, 0.4, color='blue', label='Training')
    plt.bar(X_axis+0.2, val_data, 0.4, color='red', label='Validation')

    plt.title(plot_title, fontsize=1)
    plt.xticks(X_axis, labels)
    plt.xlabel(x_label, fontsize=14)
    plt.ylabel(y_label, fontsize=14)
    plt.legend()
    plt.grid(True)

    # Add percentage values to the bar graph
    for i, (trn, val) in enumerate(zip(train_data, val_data)):
        plt.text(i-0.25, trn+0.01, f"{trn*100:.1f}%", color='black', fontweight='bold')
        plt.text(i+0.15, val+0.01, f"{val*100:.1f}%", color='black', fontweight='bold')

    plt.show()
    print()

model_name = "SVM_result"
ploting_result(model_name,
            "Precision",
            "precision in 10 folds",
            SVM_result["Training Precision scores"],
            SVM_result["Validation Precision scores"])

ploting_result(model_name,
            "Recall",
            "Recall scores in 10 Folds",
            SVM_result["Training Recall scores"],
            SVM_result["Validation Recall scores"])

ploting_result(model_name,
            "F1",
            "F1 Scores in 10 Folds",
            SVM_result["Training F1 scores"],
            SVM_result["Validation F1 scores"])

ploting_result(model_name,
            "Accuracy",
            "Accuracy scores in 10 Folds",
            SVM_result["Training Accuracy scores"],
            SVM_result["Validation Accuracy scores"])

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data.csv")

df['diagnosis'].value_counts()

df.head()

df= df.drop(['Unnamed: 32','id'],axis=1)

p = df.iloc[:,2:32]
q = df.diagnosis

p_train, p_test, q_train, q_test = train_test_split(p, q, test_size=0.25, random_state=15)

sc = StandardScaler()

p_train = sc.fit_transform(p_train)
p_test= sc.transform(p_test)

svc1= SVC(probability=True)

svc1.fit(p_train,q_train)

y_predict_svc2 = svc1.predict(p_test)

y_predict_svc3=svc1.decision_function(p_test)

le=LabelEncoder()
y_predict_svc3=le.fit_transform(y_predict_svc3)

cm = confusion_matrix(q_test, y_predict_svc2)
print("Confusion matrix:\n",cm)

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(q_test, y_predict_svc2))
creport = classification_report(q_test, y_predict_svc2)
print("Classification report:\n",creport)
plt.show()

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import LabelEncoder

# transform labels to binary values
le = LabelEncoder()
y_test_bin = le.fit_transform(y_test)
q_test_bin=le.fit_transform(q_test)

# calculate roc curve and auc for sklearn and SVM models
sk_fpr, sk_tpr, _ = roc_curve(y_test_bin, y_pred_svc2)
auc_sk = auc(sk_fpr, sk_tpr)

svm_fpr, svm_tpr, _ = roc_curve(q_test_bin, y_predict_svc3)
auc_svm = auc(svm_fpr, svm_tpr)

# plot ROC curves
plt.figure(figsize=(5,5), dpi=100)
plt.plot(svm_fpr, svm_tpr, linestyle='-', label='SVM (auc=%.3f)' % auc_svm)
plt.plot(sk_fpr, sk_tpr, linestyle='-', label='skfolds (auc=%.3f)' % auc_sk)
plt.xlabel('False positive rate-->')
plt.ylabel('True positive rate -->')
plt.legend(loc="lower right")
plt.show()